{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3zEWyJx/SntTBgUZCre/V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2003Yash/huggingface-deployment-in-Sagemaker/blob/main/Huggingface_Sagemaker_Deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create environment"
      ],
      "metadata": {
        "id": "OQ06IbOZs_k2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnXCpcz5q1O_"
      },
      "outputs": [],
      "source": [
        "!pip install sagemaker -U # installs any updates happened to sagemaker version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create bucket"
      ],
      "metadata": {
        "id": "NbG8rM9StCAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sagemaker\n",
        "import boto3\n",
        "sess = sagemaker.Session()\n",
        "\n",
        "sagemaker_session_bucket=None #  sagemaker session bucket -> used for uploading data, models and logs\n",
        "                              # sagemaker will automatically create this bucket if it not exists\n",
        "\n",
        "\n",
        "if sagemaker_session_bucket is None and sess is not None:\n",
        "    sagemaker_session_bucket = sess.default_bucket() # set to default bucket if a bucket name is not given"
      ],
      "metadata": {
        "id": "hUIo0BitrcP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Role Mangement"
      ],
      "metadata": {
        "id": "sNPRfXvztF8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    role = sagemaker.get_execution_role() # try calling role directly\n",
        "\n",
        "except ValueError:\n",
        "    iam = boto3.client('iam')\n",
        "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn'] # it direct call fails use this code\n",
        "\n",
        "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
        "\n",
        "print(f\"sagemaker role arn: {role}\") # we use roles to call models\n",
        "print(f\"sagemaker session region: {sess.boto_region_name}\")"
      ],
      "metadata": {
        "id": "WWIR4_yytIXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Model from HF-Hub"
      ],
      "metadata": {
        "id": "FZUexas2u0KS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.huggingface.model import HuggingFaceModel\n",
        "\n",
        "# Hub model configuration <https://huggingface.co/models>\n",
        "hub = {\n",
        "  'HF_MODEL_ID':'distilbert-base-uncased-distilled-squad', # model_id from hf.co/models\n",
        "  'HF_TASK':'question-answering'                           # NLP task you want to use for predictions\n",
        "}"
      ],
      "metadata": {
        "id": "iT351b4mtiJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create model from imported Model along with environment config"
      ],
      "metadata": {
        "id": "CKssfPi1vB9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create Hugging Face Model Class\n",
        "huggingface_model = HuggingFaceModel(\n",
        "   env=hub,                                                # configuration for loading model from Hub\n",
        "   role=role,                                              # IAM role with permissions to create an endpoint\n",
        "   transformers_version=\"4.26\",                             # Transformers version used\n",
        "   pytorch_version=\"1.13\",                                  # PyTorch version used\n",
        "   py_version='py39',                                      # Python version used\n",
        ")"
      ],
      "metadata": {
        "id": "VUFtC30At9xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deploy Model"
      ],
      "metadata": {
        "id": "8g_t6tqgvLGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# deploy model to SageMaker Inference\n",
        "predictor = huggingface_model.deploy(\n",
        "   initial_instance_count=1,\n",
        "   instance_type=\"ml.m5.xlarge\"\n",
        ")\n",
        "\n",
        "# O/P = -----!\n",
        "# each - in output defines avg minute taken to deploy it and it usually takes 6-7 minutes"
      ],
      "metadata": {
        "id": "_epRcXobuBbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example request: you always need to define \"inputs\"\n",
        "data = {\n",
        "\"inputs\": {\n",
        "\t\"question\": \"What is used for inference?\",\n",
        "\t\"context\": \"My Name is Philipp and I live in Nuremberg. This model is used with sagemaker for inference.\"\n",
        "\t}\n",
        "}"
      ],
      "metadata": {
        "id": "8w_JQp2OuGV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.predict(data)"
      ],
      "metadata": {
        "id": "I02dtlRiue-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# O/P = {'score': 0.9987204670906067, 'start': 68, 'end': 77, 'answer': 'sagemaker'}"
      ],
      "metadata": {
        "id": "JPT92HCUuh8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "new question"
      ],
      "metadata": {
        "id": "3PQBfZgRuWnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "\"inputs\": {\n",
        "\t\"question\": \"What does Krish teach?\",\n",
        "\t\"context\": \"My Name is Krish and  I teach data science.\"\n",
        "\t}\n",
        "}"
      ],
      "metadata": {
        "id": "hE06OOYquRXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.predict(data)"
      ],
      "metadata": {
        "id": "XOTPEO2iuYpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# O/P = {'score': 0.9854100942611694, 'start': 30, 'end': 42, 'answer': 'data science'}"
      ],
      "metadata": {
        "id": "7GG7haMHuauD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Endpoints are visible in Sagemaker -> deployments -> End points**"
      ],
      "metadata": {
        "id": "2OXPsra9vhV8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean the endponits and buckets"
      ],
      "metadata": {
        "id": "jglcFG-wvyuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MANUNALLY DELETE THE BUCKET INSIDE S3\n",
        "SELECT NOTEBOOK INSTANCE -> STOP\n",
        "-> (AFTER IT STOPS) DELET"
      ],
      "metadata": {
        "id": "PUpm5mYEz62Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}